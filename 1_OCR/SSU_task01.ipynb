{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec78937",
   "metadata": {},
   "source": [
    "## Import modules and set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bc67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# from tqdm import tqdm\n",
    "\n",
    "ALPHABET_LEN = 26\n",
    "XI_LEN = 8256  # n pixels + all pixel pairs\n",
    "BIAS = 1  # multi class classifier bias\n",
    "\n",
    "alphabet = {0: \"a\", 1: \"b\", 2: \"c\", 3: \"d\", 4: \"e\", 5: \"f\", 6: \"g\", 7: \"h\", 8: \"i\", 9: \"j\", 10: \"k\",\n",
    "            11: \"l\", 12: \"m\", 13: \"n\", 14: \"o\", 15: \"p\", 16: \"q\", 17: \"r\", 18: \"s\", 19: \"t\", 20: \"u\",\n",
    "            21: \"v\", 22: \"w\", 23: \"x\", 24: \"y\", 25: \"z\"}\n",
    "\n",
    "\n",
    "def get_keys_from_value(my_dict, val):\n",
    "    for key, val_i in my_dict.items():\n",
    "        if val_i == val:\n",
    "            return key\n",
    "    print(\"Error, no key found!\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# all 20 classified sequences with lengths equal to the index\n",
    "sequences = [[],\n",
    "             [],\n",
    "             [\"bo\", \"ty\"],\n",
    "             [\"max\"],\n",
    "             [\"cruz\", \"drew\", \"greg\", \"hugh\", \"jack\"],\n",
    "             [\"brock\", \"devyn\", \"elvis\", \"floyd\", \"quinn\", \"ralph\", \"steve\", \"tariq\"],\n",
    "             [\"dwight\", \"joseph\", \"philip\"],\n",
    "             [],\n",
    "             [\"clifford\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951c1bd",
   "metadata": {},
   "source": [
    "## Load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b148140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: ocr_names_images/trn\n",
      "Data loaded: ocr_names_images/tst\n"
     ]
    }
   ],
   "source": [
    "# load a single image\n",
    "def load_image(img_path):\n",
    "    space_idx = img_path.rfind('_')\n",
    "    Y = img_path[space_idx + 1:-4]\n",
    "    # n = img_path[space_idx-4:space_idx]\n",
    "    # print(n, Y)\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    img_mat = np.asarray(img)\n",
    "\n",
    "    n_letters = len(Y)\n",
    "    im_height = int(img_mat.shape[0])\n",
    "    im_width = int(img_mat.shape[1] / n_letters)\n",
    "    n_pixels = im_height * im_width\n",
    "\n",
    "    X = np.zeros([int(n_pixels + (n_pixels - 1) * n_pixels / 2), n_letters])\n",
    "\n",
    "    # compute features of each letter\n",
    "    for i in range(n_letters):\n",
    "        # add pixel values in the feature array\n",
    "        letter = img_mat[:, im_width * i:im_width * (i + 1)] / 255\n",
    "        X[0:n_pixels, i] = letter.flatten()\n",
    "\n",
    "        # add the multiples of each pair of the pixels in the f. a.\n",
    "        index = n_pixels\n",
    "        for j in range(0, n_pixels - 1):\n",
    "            for k in range(j + 1, n_pixels):\n",
    "                X[index, i] = X[j, i] * X[k, i]\n",
    "                index += 1\n",
    "\n",
    "        X[:, i] /= np.linalg.norm(X[:, i])\n",
    "\n",
    "    return X, Y, img\n",
    "\n",
    "\n",
    "# load all image from a folder\n",
    "def load_images(img_folder):\n",
    "    X = []\n",
    "    Y = []\n",
    "    img = []\n",
    "\n",
    "    for file in listdir(img_folder):\n",
    "        path = join(img_folder, file)\n",
    "        if isfile(path):\n",
    "            X_i, Y_i, img_i = load_image(path)\n",
    "            X.append(X_i)\n",
    "            Y.append(Y_i)\n",
    "            img.append(img_i)\n",
    "\n",
    "    print(\"Data loaded:\", img_folder)\n",
    "    return X, Y, img\n",
    "\n",
    "trn_X, trn_Y, trn_img = load_images('ocr_names_images/trn')\n",
    "test_X, test_Y, test_img = load_images('ocr_names_images/tst')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc5c3a",
   "metadata": {},
   "source": [
    "## Common functions for all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df0cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns na array P = [0 ... 0, x_i, 0 ... 0]\n",
    "def phi(x_i, y_idx):\n",
    "    phi_xy = np.zeros((ALPHABET_LEN * XI_LEN, 1))\n",
    "    phi_xy[y_idx * XI_LEN: (y_idx + 1) * XI_LEN] = x_i\n",
    "\n",
    "    return phi_xy\n",
    "\n",
    "\n",
    "# with biases added at the end of x_i\n",
    "# returns na array P = [0 ... 0, x_i, 1, 0 ... 0]\n",
    "def phi_b(x_i, y_idx):\n",
    "    phi_xy = np.zeros((ALPHABET_LEN * (XI_LEN + 1), 1))\n",
    "\n",
    "    phi_xy[y_idx * (XI_LEN + 1): (y_idx + 1) * (XI_LEN + 1) - 1] = x_i\n",
    "    phi_xy[(y_idx + 1) * (XI_LEN + 1) - 1] = 1\n",
    "\n",
    "    return phi_xy\n",
    "\n",
    "\n",
    "# get prediction values for one letter from features x_i\n",
    "def letter_predictor(w, x_i):\n",
    "    predictions_list = np.zeros(ALPHABET_LEN)\n",
    "    for i in range(ALPHABET_LEN):\n",
    "        y_pred = (w.T @ phi_b(x_i, i))[0][0] if BIAS else (w.T @ phi(x_i, i))[0][0]\n",
    "        predictions_list[i] = y_pred\n",
    "    return predictions_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a58979",
   "metadata": {},
   "source": [
    "## Independent linear multi-class classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f10be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate of 0: 81\n",
      "Success rate of 1: 260\n",
      "Success rate of 2: 359\n",
      "Success rate of 3: 484\n",
      "Success rate of 4: 616\n",
      "Success rate of 5: 663\n",
      "Success rate of 6: 718\n",
      "Success rate of 7: 739\n",
      "Success rate of 8: 781\n",
      "Success rate of 9: 827\n",
      "Success rate of 10: 842\n",
      "Success rate of 11: 857\n",
      "Success rate of 12: 874\n",
      "Success rate of 13: 913\n",
      "Success rate of 14: 914\n",
      "Success rate of 15: 911\n",
      "Success rate of 16: 920\n",
      "Success rate of 17: 923\n",
      "Success rate of 18: 927\n",
      "Success rate of 19: 938\n",
      "Success rate of 20: 958\n",
      "Success rate of 21: 933\n",
      "Success rate of 22: 953\n",
      "Success rate of 23: 972\n",
      "Success rate of 24: 960\n",
      "Success rate of 25: 965\n",
      "Success rate of 26: 965\n",
      "Success rate of 27: 970\n",
      "Success rate of 28: 969\n",
      "Success rate of 29: 974\n",
      "Success rate of 30: 977\n",
      "Success rate of 31: 996\n",
      "Success rate of 32: 991\n",
      "Success rate of 33: 976\n",
      "Success rate of 34: 996\n",
      "Success rate of 35: 994\n",
      "Success rate of 36: 988\n",
      "Success rate of 37: 979\n",
      "Success rate of 38: 982\n",
      "Success rate of 39: 987\n",
      "Success rate of 40: 998\n",
      "Success rate of 41: 998\n",
      "Success rate of 42: 1000\n",
      "N of iterations for success rate 1000: 43\n",
      "R_char is: 0.2587346553352219\n",
      "R_seq is: 0.69\n"
     ]
    }
   ],
   "source": [
    "# prediction of the sequence (Y_pred) from image sequence(X) and weights (w) with weights update\n",
    "# for each letter independently\n",
    "def multi_class_classifier(Y_ref, w, X, train=True):\n",
    "    word_error = 0\n",
    "    word_len = len(Y_ref)\n",
    "    Y_pred_idx = np.zeros(len(Y_ref), dtype=int)\n",
    "    for j in range(word_len):\n",
    "        x_j = np.vstack(X[:, j])\n",
    "        predictions_list = letter_predictor(w, x_j)\n",
    "        Y_pred_idx[j] = np.argmax(predictions_list)\n",
    "        \n",
    "    Y_ref_idx = np.zeros(word_len, dtype=int)\n",
    "    for i in range(word_len):\n",
    "        Y_ref_idx[i] = get_keys_from_value(alphabet, Y_ref[i])\n",
    "\n",
    "    for j in range(word_len):\n",
    "        if Y_pred_idx[j] != Y_ref_idx[j]:\n",
    "            if train:\n",
    "                x_i = np.vstack(X[:, j])\n",
    "                w += phi_b(x_i, Y_ref_idx[j]) if BIAS else phi(x_i, Y_ref_idx[j])\n",
    "                w -= phi_b(x_i, Y_pred_idx[j]) if BIAS else phi(x_i, Y_pred_idx[j])\n",
    "            word_error += 1\n",
    "\n",
    "    return w, word_error\n",
    "\n",
    "\n",
    "# learn parameters\n",
    "def train_weights_1(train_X, train_Y):\n",
    "    train_dataset_len = 1000\n",
    "\n",
    "    # weights = [w_1, w_2 ... w_26]\n",
    "    weights = np.zeros((ALPHABET_LEN * (XI_LEN + 1), 1)) if BIAS else \\\n",
    "                np.zeros((ALPHABET_LEN * XI_LEN, 1))\n",
    "\n",
    "    n_correct_words = 0\n",
    "    n_iterations = 0\n",
    "    min_success_rate = 1000\n",
    "    while n_correct_words < min_success_rate:\n",
    "        n_correct_words = 0\n",
    "        for i in range(train_dataset_len):\n",
    "            X = train_X[i]\n",
    "            Y = train_Y[i]\n",
    "            weights, word_error = multi_class_classifier(Y, weights, X, True)\n",
    "            if word_error == 0:\n",
    "                n_correct_words += 1\n",
    "        print(\"Success rate of %d: %d\" % (n_iterations, n_correct_words))\n",
    "        n_iterations += 1\n",
    "\n",
    "    print(\"N of iterations for success rate %d: %d\" % (min_success_rate, n_iterations))\n",
    "    return weights\n",
    "\n",
    "\n",
    "def evaluate_model_1(test_X, test_Y, weights):\n",
    "    n_words = 500\n",
    "    n_wrong_words = 0\n",
    "    n_letters = 0\n",
    "    n_wrong_letters = 0\n",
    "\n",
    "    for i in range(n_words):\n",
    "        X = test_X[i]\n",
    "        Y = test_Y[i]\n",
    "        weights, word_error = multi_class_classifier(Y, weights, X, False)\n",
    "\n",
    "        if word_error != 0:\n",
    "            n_wrong_words += 1\n",
    "        n_letters += len(Y)\n",
    "        n_wrong_letters += word_error\n",
    "\n",
    "    R_char = n_wrong_letters / n_letters\n",
    "    R_seq = n_wrong_words / n_words\n",
    "\n",
    "    print(\"R_char is:\", R_char)\n",
    "    print(\"R_seq is:\", R_seq)\n",
    "    return\n",
    "\n",
    "\n",
    "weights = train_weights_1(trn_X, trn_Y)\n",
    "evaluate_model_1(test_X, test_Y, weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b0f02",
   "metadata": {},
   "source": [
    "## Linear structured classifier modeling pair-wise dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31f4525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate of 0: 463\n",
      "Success rate of 1: 756\n",
      "Success rate of 2: 865\n",
      "Success rate of 3: 903\n",
      "Success rate of 4: 923\n",
      "Success rate of 5: 941\n",
      "Success rate of 6: 962\n",
      "Success rate of 7: 971\n",
      "Success rate of 8: 969\n",
      "Success rate of 9: 980\n",
      "Success rate of 10: 990\n",
      "Success rate of 11: 989\n",
      "Success rate of 12: 993\n",
      "Success rate of 13: 990\n",
      "Success rate of 14: 959\n",
      "Success rate of 15: 987\n",
      "Success rate of 16: 986\n",
      "Success rate of 17: 996\n",
      "Success rate of 18: 998\n",
      "Success rate of 19: 1000\n",
      "N of iterations for success rate 1000: 20\n",
      "R_char is: 0.054296506137865914\n",
      "R_seq is: 0.112\n"
     ]
    }
   ],
   "source": [
    "def find_next_y(Q, w, g, F_list, Y_pred, index):\n",
    "    q_list = Q[:, index]\n",
    "    new_F_list = np.zeros(ALPHABET_LEN)\n",
    "    for i in range(ALPHABET_LEN):\n",
    "        new_F_list[i] = q_list[i] + max(F_list + g[:, i])\n",
    "\n",
    "    if index == len(Y_pred)-1:\n",
    "        Y_pred[index] = np.argmax(new_F_list)\n",
    "    else:\n",
    "        Y_pred = find_next_y(Q, w, g, new_F_list, Y_pred, index+1)\n",
    "\n",
    "    Y_pred[index-1] = np.argmax(F_list + g[:, Y_pred[index]])\n",
    "    return Y_pred\n",
    "\n",
    "\n",
    "def structured_classifier_pairs(Y_ref, w, g, X, train=True):\n",
    "    index = 0\n",
    "\n",
    "    Q = np.zeros((ALPHABET_LEN, len(Y_ref)))\n",
    "    for j in range(len(Y_ref)):\n",
    "        x_i = np.vstack(X[:, j])\n",
    "        Q[:, j] = letter_predictor(w, x_i)\n",
    "    q_list = Q[:, index]\n",
    "\n",
    "    Y_pred_idx = np.zeros(len(Y_ref), dtype=int)\n",
    "    Y_pred_idx = find_next_y(Q, w, g, q_list, Y_pred_idx, index+1)\n",
    "\n",
    "    Y_ref_idx = np.zeros(len(Y_ref), dtype=int)\n",
    "    for i in range(len(Y_ref)):\n",
    "        Y_ref_idx[i] = get_keys_from_value(alphabet, Y_ref[i])\n",
    "\n",
    "    word_error = 0\n",
    "    for j in range(len(Y_ref)):\n",
    "        if Y_pred_idx[j] != Y_ref_idx[j]:\n",
    "            word_error += 1\n",
    "            if train:\n",
    "                x_i = np.vstack(X[:, j])\n",
    "                w += phi_b(x_i, Y_ref_idx[j]) if BIAS else phi(x_i, Y_ref_idx[j])\n",
    "                w -= phi_b(x_i, Y_pred_idx[j]) if BIAS else phi(x_i, Y_pred_idx[j])\n",
    "        if train and j > 0:\n",
    "            if Y_pred_idx[j] != Y_ref_idx[j] and Y_pred_idx[j-1] == Y_ref_idx[j-1]:\n",
    "                g[Y_ref_idx[j-1], Y_pred_idx[j]] -= 1\n",
    "                g[Y_ref_idx[j-1], Y_ref_idx[j]] += 1\n",
    "            elif Y_pred_idx[j] == Y_ref_idx[j] and Y_pred_idx[j-1] != Y_ref_idx[j-1]:\n",
    "                g[Y_pred_idx[j-1], Y_ref_idx[j]] -= 1\n",
    "                g[Y_ref_idx[j-1], Y_ref_idx[j]] += 1\n",
    "            elif Y_pred_idx[j] != Y_ref_idx[j] and Y_pred_idx[j-1] != Y_ref_idx[j-1]:\n",
    "                g[Y_pred_idx[j-1], Y_pred_idx[j]] -= 1\n",
    "                g[Y_ref_idx[j-1], Y_ref_idx[j]] += 1\n",
    "\n",
    "    return w, g, word_error\n",
    "\n",
    "\n",
    "# learn parameters\n",
    "def train_weights_2(train_X, train_Y):\n",
    "    train_dataset_len = 1000\n",
    "\n",
    "    # weights = [w_1, w_2 ... w_26]\n",
    "    weights = np.zeros((ALPHABET_LEN * (XI_LEN + 1), 1))  # with biases\n",
    "\n",
    "    # letter transition matrix = [g_1; g_2; ... g_26]\n",
    "    # g[i,j] .. value of probable transition from letter i to the following letter j\n",
    "    g = np.zeros((ALPHABET_LEN, ALPHABET_LEN))\n",
    "\n",
    "    n_correct_words = 0\n",
    "    n_iterations = 0\n",
    "    min_success_rate = 1000\n",
    "    while n_correct_words < min_success_rate:\n",
    "        n_correct_words = 0\n",
    "        for i in range(train_dataset_len):\n",
    "            X = train_X[i]\n",
    "            Y = train_Y[i]\n",
    "            weights, g, word_error = structured_classifier_pairs(Y, weights, g, X, True)\n",
    "\n",
    "            if word_error == 0:\n",
    "                n_correct_words += 1\n",
    "        print(\"Success rate of %d: %d\" % (n_iterations, n_correct_words))\n",
    "        n_iterations += 1\n",
    "\n",
    "    print(\"N of iterations for success rate %d: %d\" % (min_success_rate, n_iterations))\n",
    "    return weights, g\n",
    "\n",
    "\n",
    "def evaluate_model_2(test_X, test_Y, weights, g):\n",
    "    n_words = 500\n",
    "    n_wrong_words = 0\n",
    "    n_letters = 0\n",
    "    n_wrong_letters = 0\n",
    "\n",
    "    for i in range(n_words):\n",
    "        X = test_X[i]\n",
    "        Y = test_Y[i]\n",
    "        weights, g, word_error = structured_classifier_pairs(Y, weights, g, X, False)\n",
    "\n",
    "        if word_error != 0:\n",
    "            n_wrong_words += 1\n",
    "        n_letters += len(Y)\n",
    "        n_wrong_letters += word_error\n",
    "\n",
    "    R_char = n_wrong_letters / n_letters\n",
    "    R_seq = n_wrong_words / n_words\n",
    "\n",
    "    print(\"R_char is:\", R_char)\n",
    "    print(\"R_seq is:\", R_seq)\n",
    "    return\n",
    "\n",
    "\n",
    "weights, g = train_weights_2(trn_X, trn_Y)\n",
    "evaluate_model_2(test_X, test_Y, weights, g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70acb6b4",
   "metadata": {},
   "source": [
    "## Linear structured classifier for fixed number of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87f02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate of 0: 866\n",
      "Success rate of 1: 981\n",
      "Success rate of 2: 983\n",
      "Success rate of 3: 995\n",
      "Success rate of 4: 1000\n",
      "N of iterations for success rate 1000: 5\n",
      "R_char is: 0.020302171860245515\n",
      "R_seq is: 0.024\n"
     ]
    }
   ],
   "source": [
    "# prediction of the sequence\n",
    "def structured_classifier_fixed(Y_ref, w, X, train=True):\n",
    "    word_error = 0\n",
    "    word_len = len(Y_ref)\n",
    "    sequences_L = sequences[word_len]\n",
    "    V_seq_param = np.zeros(len(sequences_L))\n",
    "    Q = np.zeros((ALPHABET_LEN, word_len))\n",
    "    for j in range(word_len):\n",
    "        x_i = np.vstack(X[:, j])\n",
    "        Q[:, j] = letter_predictor(w, x_i)\n",
    "\n",
    "\n",
    "    Y_pred = np.zeros((word_len))\n",
    "    max_seq_score = -1000\n",
    "    max_seq_idx = 0\n",
    "    for j in range(len(sequences_L)):\n",
    "        seq = sequences_L[j]\n",
    "        score = 0\n",
    "        for k in range(word_len):\n",
    "            letter_idx = get_keys_from_value(alphabet, seq[k])\n",
    "            score += Q[letter_idx, k]  # Q[letter_type, word_position]\n",
    "        score += V_seq_param[j]\n",
    "        if score > max_seq_score:\n",
    "            max_seq_score = score\n",
    "            max_seq_idx = j\n",
    "    Y_pred = sequences_L[max_seq_idx]\n",
    "\n",
    "    Y_ref_idx = np.zeros(len(Y_ref), dtype=int)\n",
    "    Y_pred_idx = np.zeros(len(Y_ref), dtype=int)\n",
    "    for i in range(word_len):\n",
    "        Y_ref_idx[i] = get_keys_from_value(alphabet, Y_ref[i])\n",
    "        Y_pred_idx[i] = get_keys_from_value(alphabet, Y_pred[i])\n",
    "\n",
    "    for j in range(word_len):\n",
    "        if Y_pred_idx[j] != Y_ref_idx[j]:\n",
    "            if train:\n",
    "                x_i = np.vstack(X[:, j])\n",
    "                w += phi_b(x_i, Y_ref_idx[j]) if BIAS else phi(x_i, Y_ref_idx[j])\n",
    "                w -= phi_b(x_i, Y_pred_idx[j]) if BIAS else phi(x_i, Y_pred_idx[j])\n",
    "            word_error += 1\n",
    "\n",
    "    if train and word_error > 0:\n",
    "        v_ref_idx = 0  # correct sequence (from training data) index in sequences_L list\n",
    "        for j in range(len(sequences_L)):\n",
    "            seq = sequences_L[j]\n",
    "            for k in range(word_len):\n",
    "                letter = seq[k]\n",
    "                if Y_pred[k] != letter:\n",
    "                    break\n",
    "                v_ref_idx = j\n",
    "        V_seq_param[v_ref_idx] += 1\n",
    "        V_seq_param[max_seq_idx] -= 1\n",
    "\n",
    "    return w, word_error\n",
    "\n",
    "\n",
    "# learn parameters\n",
    "def train_weights_3(train_X, train_Y):\n",
    "    train_dataset_len = 1000\n",
    "\n",
    "    # weights = [w_1, w_2 ... w_26]\n",
    "    weights = np.zeros((ALPHABET_LEN * (XI_LEN + 1), 1))  # with biases\n",
    "\n",
    "    # letter transition matrix = [g_1; g_2; ... g_26]\n",
    "    # g[i,j] .. value of probable transition from letter i to the following letter j\n",
    "    g = np.zeros((ALPHABET_LEN, ALPHABET_LEN))\n",
    "\n",
    "    n_correct_words = 0\n",
    "    n_iterations = 0\n",
    "    min_success_rate = 1000\n",
    "    while n_correct_words < min_success_rate:\n",
    "        n_correct_words = 0\n",
    "        for i in range(train_dataset_len):\n",
    "            X = train_X[i]\n",
    "            Y = train_Y[i]\n",
    "            weights, word_error = structured_classifier_fixed(Y, weights, X, True)\n",
    "\n",
    "            if word_error == 0:\n",
    "                n_correct_words += 1\n",
    "        print(\"Success rate of %d: %d\" % (n_iterations, n_correct_words))\n",
    "        n_iterations += 1\n",
    "\n",
    "    print(\"N of iterations for success rate %d: %d\" % (min_success_rate, n_iterations))\n",
    "    return weights\n",
    "\n",
    "\n",
    "def evaluate_model_3(test_X, test_Y, weights):\n",
    "    n_words = 500\n",
    "    n_wrong_words = 0\n",
    "    n_letters = 0\n",
    "    n_wrong_letters = 0\n",
    "\n",
    "    for i in range(n_words):\n",
    "        X = test_X[i]\n",
    "        Y = test_Y[i]\n",
    "        weights, word_error = structured_classifier_fixed(Y, weights, X, False)\n",
    "\n",
    "        if word_error != 0:\n",
    "            n_wrong_words += 1\n",
    "        n_letters += len(Y)\n",
    "        n_wrong_letters += word_error\n",
    "\n",
    "    R_char = n_wrong_letters / n_letters\n",
    "    R_seq = n_wrong_words / n_words\n",
    "\n",
    "    print(\"R_char is:\", R_char)\n",
    "    print(\"R_seq is:\", R_seq)\n",
    "    return\n",
    "\n",
    "\n",
    "weights = train_weights_3(trn_X, trn_Y)\n",
    "evaluate_model_3(test_X, test_Y, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a39ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
