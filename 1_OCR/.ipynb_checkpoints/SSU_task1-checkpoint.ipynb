{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "#import sys\n",
    "#import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "\n",
    "ALPHABET_LEN = 26\n",
    "XI_LEN = 8256  # n pixels + all pixel pairs\n",
    "MCC_BIAS = 1  # multi class classifier bias\n",
    "\n",
    "\n",
    "alphabet = {0: \"a\",\n",
    "            1: \"b\",\n",
    "            2: \"c\",\n",
    "            3: \"d\",\n",
    "            4: \"e\",\n",
    "            5: \"f\",\n",
    "            6: \"g\",\n",
    "            7: \"h\",\n",
    "            8: \"i\",\n",
    "            9: \"j\",\n",
    "            10: \"k\",\n",
    "            11: \"l\",\n",
    "            12: \"m\",\n",
    "            13: \"n\",\n",
    "            14: \"o\",\n",
    "            15: \"p\",\n",
    "            16: \"q\",\n",
    "            17: \"r\",\n",
    "            18: \"s\",\n",
    "            19: \"t\",\n",
    "            20: \"u\",\n",
    "            21: \"v\",\n",
    "            22: \"w\",\n",
    "            23: \"x\",\n",
    "            24: \"y\",\n",
    "            25: \"z\"}\n",
    "\n",
    "# all 20 classified sequences with lengths equal to the index\n",
    "sequences = [[],\n",
    "             [],\n",
    "             [\"bo\", \"ty\"],\n",
    "             [\"max\"],\n",
    "             [\"cruz\", \"drew\", \"greg\", \"hugh\", \"jack\"],\n",
    "             [\"brock\", \"devyn\", \"elvis\", \"floyd\", \"quinn\", \"ralph\", \"steve\", \"tariq\"],\n",
    "             [\"dwight\", \"joseph\", \"philip\"],\n",
    "             [],\n",
    "             [\"clifford\"]]\n",
    "\n",
    "\n",
    "# load a single image\n",
    "def load_image(img_path):\n",
    "\n",
    "    space_idx = img_path.rfind('_')\n",
    "    Y = img_path[space_idx+1:-4]\n",
    "    # n = img_path[space_idx-4:space_idx]\n",
    "    # print(n, Y)\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    img_mat = np.asarray(img)\n",
    "    \n",
    "    n_letters = len(Y)\n",
    "    im_height = int(img_mat.shape[0])\n",
    "    im_width = int(img_mat.shape[1]/n_letters)\n",
    "    n_pixels = im_height*im_width\n",
    "    \n",
    "    X = np.zeros([int(n_pixels+(n_pixels-1)*n_pixels/2), n_letters])\n",
    "\n",
    "    # compute features of each letter\n",
    "    for i in range(n_letters):\n",
    "        # add pixel values in the feature array\n",
    "        letter = img_mat[:, im_width*i:im_width*(i+1)]/255\n",
    "        X[0:n_pixels, i] = letter.flatten()\n",
    "\n",
    "        # add the multiples of each pair of the pixels in the f. a.\n",
    "        index = n_pixels\n",
    "        for j in range(0, n_pixels-1):\n",
    "            for k in range(j+1, n_pixels):\n",
    "                X[index, i] = X[j, i]*X[k, i]\n",
    "                index += 1\n",
    "\n",
    "        X[:, i] /= np.linalg.norm(X[:, i])\n",
    "        \n",
    "    return X, Y, img\n",
    "\n",
    "\n",
    "# load all image from a folder\n",
    "def load_images(img_folder):\n",
    "    X = []\n",
    "    Y = []\n",
    "    img = []\n",
    "\n",
    "    for file in listdir(img_folder):\n",
    "        path = join(img_folder, file)\n",
    "        if isfile(path):\n",
    "            X_i, Y_i, img_i = load_image(path)\n",
    "            X.append(X_i)\n",
    "            Y.append(Y_i)\n",
    "            img.append(img_i)\n",
    "\n",
    "    print(\"Data loaded:\", img_folder)\n",
    "    return X, Y, img\n",
    "\n",
    "\n",
    "# returns na array P = [0 ... 0, x_i, 0 ... 0]\n",
    "def phi(x_i, y_idx):\n",
    "    phi_xy = np.zeros((ALPHABET_LEN * XI_LEN, 1))\n",
    "    phi_xy[y_idx * XI_LEN: (y_idx + 1) * XI_LEN] = x_i\n",
    "\n",
    "    return phi_xy\n",
    "\n",
    "\n",
    "# with biases added at the end of x_i\n",
    "# returns na array P = [0 ... 0, x_i, 1, 0 ... 0]\n",
    "def phi_b(x_i, y_idx):\n",
    "    phi_xy = np.zeros((ALPHABET_LEN * (XI_LEN + 1), 1))\n",
    "\n",
    "    phi_xy[ y_idx*(XI_LEN+1) : (y_idx+1)*(XI_LEN+1)-1 ] = x_i\n",
    "    phi_xy[ (y_idx+1)*(XI_LEN+1)-1 ] = 1\n",
    "\n",
    "    return phi_xy\n",
    "\n",
    "\n",
    "def get_keys_from_value(my_dict, val):\n",
    "    for key, val_i in my_dict.items():\n",
    "        if val_i == val:\n",
    "            return key\n",
    "    print(\"Error, no key found!\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# multi class classifier prediction for one letter\n",
    "def mcc_predictor(w, x_i):\n",
    "    predictions_list = np.zeros(ALPHABET_LEN)\n",
    "    y_idx = -1\n",
    "    y_max = -10\n",
    "    for i in range(ALPHABET_LEN):\n",
    "        if MCC_BIAS:\n",
    "            y_pred = (w.T@phi_b(x_i, i))[0][0]\n",
    "        else:\n",
    "            y_pred = (w.T@phi(x_i, i))[0][0]\n",
    "\n",
    "        predictions_list[i] = y_pred\n",
    "        if y_pred > y_max:\n",
    "            y_max = y_pred\n",
    "            y_idx = i\n",
    "\n",
    "    return y_idx\n",
    "\n",
    "\n",
    "def lsc1_predictor(w, x_i):\n",
    "    predictions_list = np.zeros(ALPHABET_LEN)\n",
    "    y_idx = -1\n",
    "    y_max = -10\n",
    "    for i in range(ALPHABET_LEN):\n",
    "        if MCC_BIAS:\n",
    "            y_pred = (w.T@phi_b(x_i, i))[0][0]\n",
    "        else:\n",
    "            y_pred = (w.T@phi(x_i, i))[0][0]\n",
    "\n",
    "        predictions_list[i] = y_pred\n",
    "        if y_pred > y_max:\n",
    "            y_max = y_pred\n",
    "            y_idx = i\n",
    "\n",
    "    return y_idx\n",
    "\n",
    "\n",
    "def lsc2_predictor(w, x_i):\n",
    "    predictions_list = np.zeros(ALPHABET_LEN)\n",
    "    y_idx = -1\n",
    "    y_max = -10\n",
    "    for i in range(ALPHABET_LEN):\n",
    "        if MCC_BIAS:\n",
    "            y_pred = (w.T@phi_b(x_i, i))[0][0]\n",
    "        else:\n",
    "            y_pred = (w.T@phi(x_i, i))[0][0]\n",
    "\n",
    "        predictions_list[i] = y_pred\n",
    "        if y_pred > y_max:\n",
    "            y_max = y_pred\n",
    "            y_idx = i\n",
    "\n",
    "    return y_idx\n",
    "\n",
    "\n",
    "# prediction of the letter (y_pred)\n",
    "def multi_class_classifier(y_ref, w, x_i, word_error):\n",
    "    y_pred_idx = mcc_predictor(w, x_i)\n",
    "    y_pred = alphabet[y_pred_idx]\n",
    "    y_ref_idx = get_keys_from_value(alphabet, y_ref)\n",
    "\n",
    "    if y_pred == y_ref:\n",
    "        # print(\"Correct prediction:\", y_pred)\n",
    "        pass\n",
    "    else:\n",
    "        # print(\"INCORRECT prediction:\", y_pred, \"is not\", y_ref)\n",
    "        if MCC_BIAS:\n",
    "            w += phi_b(x_i, y_ref_idx)\n",
    "            w -= phi_b(x_i, y_pred_idx)\n",
    "        else:\n",
    "            w += phi(x_i, y_ref_idx)\n",
    "            w -= phi(x_i, y_pred_idx)\n",
    "        word_error += 1\n",
    "    return w, word_error\n",
    "\n",
    "\n",
    "# prediction of the sequence\n",
    "def structured_classifier_pairs(y_ref, w, x_i, word_error):\n",
    "    y_pred_idx = mcc_predictor(w, x_i)\n",
    "    y_pred = alphabet[y_pred_idx]\n",
    "    y_ref_idx = get_keys_from_value(alphabet, y_ref)\n",
    "\n",
    "    if y_pred == y_ref:\n",
    "        # print(\"Correct prediction:\", y_pred)\n",
    "        pass\n",
    "    else:\n",
    "        # print(\"INCORRECT prediction:\", y_pred, \"is not\", y_ref)\n",
    "        if MCC_BIAS:\n",
    "            w += phi_b(x_i, y_ref_idx)\n",
    "            w -= phi_b(x_i, y_pred_idx)\n",
    "        else:\n",
    "            w += phi(x_i, y_ref_idx)\n",
    "            w -= phi(x_i, y_pred_idx)\n",
    "        word_error += 1\n",
    "    return w, word_error\n",
    "\n",
    "\n",
    "# prediction of the sequence\n",
    "def structured_classifier_fixed(y_ref, w, x_i, word_error):\n",
    "    y_pred_idx = mcc_predictor(w, x_i)\n",
    "    y_pred = alphabet[y_pred_idx]\n",
    "    y_ref_idx = get_keys_from_value(alphabet, y_ref)\n",
    "\n",
    "    if y_pred == y_ref:\n",
    "        # print(\"Correct prediction:\", y_pred)\n",
    "        pass\n",
    "    else:\n",
    "        # print(\"INCORRECT prediction:\", y_pred, \"is not\", y_ref)\n",
    "        if MCC_BIAS:\n",
    "            w += phi_b(x_i, y_ref_idx)\n",
    "            w -= phi_b(x_i, y_pred_idx)\n",
    "        else:\n",
    "            w += phi(x_i, y_ref_idx)\n",
    "            w -= phi(x_i, y_pred_idx)\n",
    "        word_error += 1\n",
    "    return w, word_error\n",
    "\n",
    "\n",
    "# learn parameters\n",
    "def train_weights(train_X, train_Y):\n",
    "    train_dataset_len = 1000\n",
    "\n",
    "    # weights = [w_1, w_2 ... w_26]\n",
    "    if MCC_BIAS:\n",
    "        print(\"Testing weights with biases\")\n",
    "        weights = np.zeros((ALPHABET_LEN*(XI_LEN+1), 1))  # with biases\n",
    "    else:\n",
    "        print(\"Testing weights without biases\")\n",
    "        weights = np.zeros((ALPHABET_LEN*XI_LEN, 1))\n",
    "\n",
    "    n_correct_words = 0\n",
    "    n_iterations = 0\n",
    "    min_success_rate = 1000\n",
    "    while n_correct_words < min_success_rate:\n",
    "        n_correct_words = 0\n",
    "        for i in range(train_dataset_len):\n",
    "            X = train_X[i]\n",
    "            Y = train_Y[i]\n",
    "            word_error = 0\n",
    "            for j in range(len(Y)):\n",
    "                y_ref = Y[j]\n",
    "                x_i = np.vstack(X[:, j])\n",
    "                weights, word_error = multi_class_classifier(y_ref, weights, x_i, word_error)\n",
    "            if word_error == 0:\n",
    "                n_correct_words += 1\n",
    "        print(\"Success rate of %d: %d\" % (n_iterations, n_correct_words))\n",
    "        n_iterations += 1\n",
    "\n",
    "    print(\"N of iterations for success rate %d: %d\" % (min_success_rate, n_iterations))\n",
    "    return weights\n",
    "\n",
    "\n",
    "def evaluate_model(test_X, test_Y, weights):\n",
    "    test_dataset_len = 500\n",
    "    letter_scores = np.zeros(ALPHABET_LEN)\n",
    "    letter_occurences = np.zeros(ALPHABET_LEN)\n",
    "    n_correct_words = 0\n",
    "    for i in range(test_dataset_len):\n",
    "        X = test_X[i]\n",
    "        Y = test_Y[i]\n",
    "        word_error = 0\n",
    "        for i in range(len(Y)):\n",
    "            y_ref = Y[i]\n",
    "            y_ref_idx = get_keys_from_value(alphabet, y_ref)\n",
    "            letter_occurences[y_ref_idx] += 1\n",
    "            x_i = np.vstack(X[:, i])\n",
    "            y_pred_idx = mcc_predictor(weights, x_i)\n",
    "            y_pred = alphabet[y_pred_idx]\n",
    "            if y_pred == y_ref:\n",
    "                letter_scores[y_pred_idx] += 1\n",
    "            else:\n",
    "                word_error += 1\n",
    "        if word_error == 0:\n",
    "            n_correct_words += 1\n",
    "    print(letter_scores/letter_occurences)\n",
    "    print(\"Letter accuracy is:\", sum(letter_scores/letter_occurences)/ALPHABET_LEN)\n",
    "    print(\"Word accuracy is:\", n_correct_words/test_dataset_len)\n",
    "    return\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: ocr_names_images/trn\n",
      "Data loaded: ocr_names_images/tst\n"
     ]
    }
   ],
   "source": [
    "trn_X, trn_Y, trn_img = load_images('ocr_names_images/trn')\n",
    "test_X, test_Y, test_img = load_images('ocr_names_images/tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = train_weights(trn_X, trn_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(test_X, test_Y, weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
